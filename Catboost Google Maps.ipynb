{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c35f484",
   "metadata": {},
   "source": [
    "Catboost Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost scikit-learn pandas tqdm optuna\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd, json, numpy as np, optuna, random\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "file_path = '/content/drive/MyDrive/review-South_Carolina_10.json'\n",
    "data = [json.loads(line) for line in open(file_path)]\n",
    "df = pd.DataFrame(data)[['user_id', 'gmap_id', 'rating', 'time']].dropna()\n",
    "df['timestamp'] = pd.to_datetime(df['time'], unit='ms')\n",
    "df['time_norm'] = (df['time'] - df['time'].min()) / (df['time'].max() - df['time'].min())\n",
    "\n",
    "# Feature engineering\n",
    "user_stats = df.groupby('user_id').agg(\n",
    "    user_num_reviews=('rating', 'count'),\n",
    "    user_avg_rating=('rating', 'mean'),\n",
    "    user_first_review=('timestamp', 'min')\n",
    ").reset_index()\n",
    "user_stats['user_days_since_first'] = (df['timestamp'].max() - user_stats['user_first_review']).dt.days\n",
    "\n",
    "item_stats = df.groupby('gmap_id').agg(\n",
    "    item_num_reviews=('rating', 'count'),\n",
    "    item_avg_rating=('rating', 'mean'),\n",
    "    item_first_review=('timestamp', 'min')\n",
    ").reset_index()\n",
    "item_stats['item_days_since_first'] = (df['timestamp'].max() - item_stats['item_first_review']).dt.days\n",
    "\n",
    "df = df.merge(user_stats.drop(columns='user_first_review'), on='user_id', how='left')\n",
    "df = df.merge(item_stats.drop(columns='item_first_review'), on='gmap_id', how='left')\n",
    "df.drop(columns=['timestamp'], inplace=True)\n",
    "df = df[df['user_num_reviews'] >= 3]\n",
    "df = df[df['item_num_reviews'] >= 3]\n",
    "\n",
    "# === 3. Split Dataset ===\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)\n",
    "\n",
    "cat_features = ['user_id', 'gmap_id']\n",
    "num_features = [\n",
    "    'time_norm', 'user_num_reviews', 'user_avg_rating', 'user_days_since_first',\n",
    "    'item_num_reviews', 'item_avg_rating', 'item_days_since_first'\n",
    "]\n",
    "all_features = cat_features + num_features\n",
    "\n",
    "train_pool = Pool(train_df[all_features], label=train_df['rating'], cat_features=cat_features)\n",
    "test_pool = Pool(test_df[all_features], cat_features=cat_features)\n",
    "\n",
    "final_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.02,\n",
    "    loss_function='RMSE',\n",
    "    cat_features=cat_features,\n",
    "    task_type=\"GPU\",\n",
    "    devices='0',\n",
    "    verbose=0\n",
    ")\n",
    "final_model.fit(train_pool)\n",
    "test_df['pred_rating'] = final_model.predict(test_df[all_features])\n",
    "mse = mean_squared_error(test_df['rating'], test_df['pred_rating'])\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_df['rating'], test_df['pred_rating'])\n",
    "\n",
    "print(\"\\n=== Test Set Rating Metrics ===\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "K = 10\n",
    "N_NEG = 99\n",
    "all_items = set(df['gmap_id'].unique())\n",
    "seen_items = train_val_df.groupby('user_id')['gmap_id'].apply(set).to_dict()\n",
    "test_positives = test_df[test_df['rating'] >= 4].groupby('user_id').first().reset_index()\n",
    "\n",
    "user_feats = df[['user_id', 'user_num_reviews', 'user_avg_rating', 'user_days_since_first']].drop_duplicates('user_id').set_index('user_id').to_dict('index')\n",
    "item_feats = df[['gmap_id', 'item_num_reviews', 'item_avg_rating', 'item_days_since_first']].drop_duplicates('gmap_id').set_index('gmap_id').to_dict('index')\n",
    "\n",
    "precision_list, recall_list, ndcg_list, hit_list = [], [], [], []\n",
    "\n",
    "for _, row in tqdm(test_positives.iterrows(), total=len(test_positives)):\n",
    "    user_id = row['user_id']\n",
    "    pos_item = row['gmap_id']\n",
    "\n",
    "    if user_id not in seen_items:\n",
    "        continue\n",
    "\n",
    "    user_seen = seen_items[user_id]\n",
    "    negatives = list(all_items - user_seen - {pos_item})\n",
    "    if len(negatives) < N_NEG:\n",
    "        continue\n",
    "\n",
    "    sampled_negs = random.sample(negatives, N_NEG)\n",
    "    candidate_items = [pos_item] + sampled_negs\n",
    "\n",
    "    records = []\n",
    "    for item_id in candidate_items:\n",
    "        user_f = user_feats.get(user_id)\n",
    "        item_f = item_feats.get(item_id)\n",
    "        if user_f and item_f:\n",
    "            record = {\n",
    "                'user_id': user_id,\n",
    "                'gmap_id': item_id,\n",
    "                'time_norm': 1.0,\n",
    "                **user_f,\n",
    "                **item_f\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    if len(records) < K:\n",
    "        continue\n",
    "\n",
    "    candidate_df = pd.DataFrame(records)\n",
    "    scores = final_model.predict(candidate_df[all_features])\n",
    "    candidate_df['score'] = scores\n",
    "\n",
    "    top_k = candidate_df.sort_values('score', ascending=False).head(K)\n",
    "    pred_items = top_k['gmap_id'].tolist()\n",
    "\n",
    "    hit = int(pos_item in pred_items)\n",
    "    precision = hit / K\n",
    "    recall = 1.0 if hit else 0.0\n",
    "    rank = pred_items.index(pos_item) + 1 if pos_item in pred_items else 0\n",
    "    ndcg = 1 / np.log2(rank + 1) if rank > 0 else 0.0\n",
    "\n",
    "    hit_list.append(hit)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)\n",
    "\n",
    "print(\"\\n=== Sampled Top-K Ranking Metrics ===\")\n",
    "print(f\"Precision@{K}: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Recall@{K}:    {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{K}:      {np.mean(ndcg_list):.4f}\")\n",
    "print(f\"Hit@{K}:       {np.mean(hit_list):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862aadb",
   "metadata": {},
   "source": [
    "Precision@10: 0.0034\n",
    "\n",
    "Recall@10:    0.0344\n",
    "\n",
    "NDCG@10:      0.0166\n",
    "\n",
    "Hit@10:       0.0344"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
