{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c35f484",
   "metadata": {},
   "source": [
    "Content based Recommender Net TF-IDF Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-Based Recommender System using TF-IDF and Ratings (MovieLens)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Load datasets\n",
    "movies = pd.read_csv('movies.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Merge tags into movies\n",
    "tagged = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movies = pd.merge(movies, tagged, on='movieId', how='left')\n",
    "movies['tag'] = movies['tag'].fillna('')\n",
    "\n",
    "# Combine genres and tags into one metadata string\n",
    "movies['metadata'] = movies['genres'].str.replace('|', ' ', regex=False) + ' ' + movies['tag']\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['metadata'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "movie_indices = pd.Series(movies.index, index=movies['movieId'])\n",
    "\n",
    "# Merge ratings into movies (average rating per movie)\n",
    "avg_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
    "avg_ratings.columns = ['movieId', 'avg_rating']\n",
    "movies = pd.merge(movies, avg_ratings, on='movieId', how='left')\n",
    "movies['avg_rating'] = movies['avg_rating'].fillna(0)\n",
    "\n",
    "# Recommendation function based on TF-IDF similarity and rating boost\n",
    "def content_based_recommendations(movie_id, top_n=10, rating_weight=0.2):\n",
    "    idx = movie_indices[movie_id]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Enhance similarity with average ratings\n",
    "    enhanced_scores = []\n",
    "    for i, score in sim_scores:\n",
    "        rating_boost = rating_weight * movies.iloc[i]['avg_rating'] / 5  # normalize rating to 0-1 scale\n",
    "        enhanced_scores.append((i, score + rating_boost))\n",
    "\n",
    "    enhanced_scores = sorted(enhanced_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    movie_indices_rec = [i[0] for i in enhanced_scores]\n",
    "    return movie_indices_rec\n",
    "from sklearn.metrics import ndcg_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# Evaluation with NDCG, Precision, Recall, MAP\n",
    "def evaluate_all_metrics(sample_size=100, top_n=10):\n",
    "    sample = ratings[ratings['rating'] >= 4.0].groupby('userId').sample(n=1, random_state=42)\n",
    "\n",
    "    ndcg_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    average_precisions = []\n",
    "\n",
    "    for _, row in sample.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        relevant_idx = movie_indices.get(movie_id)\n",
    "        if pd.isna(relevant_idx):\n",
    "            continue\n",
    "\n",
    "        recommendations = content_based_recommendations(movie_id, top_n=top_n)\n",
    "\n",
    "        # NDCG calculation\n",
    "        y_true = np.zeros((1, len(movies)))\n",
    "        y_score = np.zeros((1, len(movies)))\n",
    "        y_true[0, int(relevant_idx)] = 1\n",
    "        for rank, idx in enumerate(recommendations):\n",
    "            y_score[0, idx] = top_n - rank\n",
    "\n",
    "        ndcg = ndcg_score(y_true, y_score)\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "        # Precision, Recall, MAP calculation\n",
    "        relevant_set = {int(relevant_idx)}\n",
    "        recommended_set = set(recommendations)\n",
    "\n",
    "        hits = relevant_set & recommended_set\n",
    "        precision = len(hits) / top_n\n",
    "        recall = len(hits) / len(relevant_set)  # always 1 relevant item here\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "        # MAP\n",
    "        ap = 0\n",
    "        for i, rec in enumerate(recommendations):\n",
    "            if rec in relevant_set:\n",
    "                ap = 1 / (i + 1)\n",
    "                break\n",
    "        average_precisions.append(ap)\n",
    "\n",
    "    return {\n",
    "        \"Precision@10\": np.mean(precisions),\n",
    "        \"Recall@10\": np.mean(recalls),\n",
    "        \"NDCG@10\": np.mean(ndcg_scores),\n",
    "        \"MAP@10\": np.mean(average_precisions)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "results = evaluate_all_metrics(sample_size=100, top_n=10)\n",
    "metrics_table = pd.DataFrame([{\n",
    "    \"Model\": \"TF-IDF Content-Based\",\n",
    "    \"Precision@10\": results[\"Precision@10\"],\n",
    "    \"Recall@10\": results[\"Recall@10\"],\n",
    "    \"NDCG@10\": results[\"NDCG@10\"],\n",
    "    \"MAP@10\": results[\"MAP@10\"]\n",
    "}])\n",
    "\n",
    "print(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862aadb",
   "metadata": {},
   "source": [
    "Precision@10  0.015435   \n",
    "\n",
    "Recall@10     0.154351\n",
    "\n",
    "NDCG@10       0.164802\n",
    "\n",
    "MAP@10.       0.072563\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
