{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c35f484",
   "metadata": {},
   "source": [
    "SASRec and Bert Hybrid Recommender Goodreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "!pip install sentence-transformers tqdm\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "file_path = '/content/drive/MyDrive/goodreads_interactions_comics_graphic.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = [json.loads(line) for line in tqdm(lines, desc=\"Loading JSONL\")]\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df['review_text_incomplete'].str.strip() != \"\"]\n",
    "\n",
    "# Aggregate Reviews per Book\n",
    "book_reviews = df.groupby(\"book_id\")[\"review_text_incomplete\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "\n",
    "# Generate BERT Embeddings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "print(\"Generating book embeddings...\")\n",
    "book_embeddings = model.encode(\n",
    "    book_reviews['review_text_incomplete'].tolist(),\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "book_embeddings = book_embeddings.cpu()\n",
    "book_reviews['embedding'] = [emb for emb in book_embeddings]\n",
    "book_index = {book_id: idx for idx, book_id in enumerate(book_reviews['book_id'])}\n",
    "\n",
    "# Cosine Similarity Recommendation\n",
    "def recommend_books_from_user_profile(user_profile, top_k=5, exclude_ids=None):\n",
    "    exclude_ids = set(exclude_ids or [])\n",
    "    sim_scores = torch.nn.functional.cosine_similarity(user_profile, book_embeddings)\n",
    "\n",
    "\n",
    "    for idx, book_id in enumerate(book_reviews['book_id']):\n",
    "        if book_id in exclude_ids:\n",
    "            sim_scores[idx] = -1\n",
    "\n",
    "    topk = torch.topk(sim_scores, top_k)\n",
    "    indices = topk.indices.cpu().numpy()\n",
    "    return [book_reviews.iloc[i]['book_id'] for i in indices]\n",
    "\n",
    "# Evaluation Metrics\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    return len(set(recommended[:k]) & set(relevant)) / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    return len(set(recommended[:k]) & set(relevant)) / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    dcg = sum([1 / np.log2(i + 2) if item in relevant else 0 for i, item in enumerate(recommended[:k])])\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(relevant), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def map_at_k(recommended, relevant, k):\n",
    "    hits = 0\n",
    "    sum_precisions = 0\n",
    "    for i, item in enumerate(recommended[:k]):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / min(len(relevant), k) if relevant else 0\n",
    "\n",
    "# Evaluation Loop\n",
    "k = 10\n",
    "precision_list, recall_list, ndcg_list, map_list = [], [], [], []\n",
    "\n",
    "print(\"Evaluating recommender...\")\n",
    "for user_id, group in tqdm(df.groupby(\"user_id\"), desc=\"Users\"):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "\n",
    "    books = group['book_id'].tolist()\n",
    "    test_book = books[-1]\n",
    "    train_books = [b for b in books[:-1] if b in book_index]\n",
    "\n",
    "    if not train_books or test_book not in book_index:\n",
    "        continue\n",
    "\n",
    "    train_embs = torch.stack([book_reviews.iloc[book_index[b]]['embedding'] for b in train_books])\n",
    "    user_profile = train_embs.median(dim=0).values.unsqueeze(0).cpu()\n",
    "\n",
    "    recommended = recommend_books_from_user_profile(user_profile, top_k=k, exclude_ids=train_books)\n",
    "    relevant = [test_book]\n",
    "\n",
    "    precision_list.append(precision_at_k(recommended, relevant, k))\n",
    "    recall_list.append(recall_at_k(recommended, relevant, k))\n",
    "    ndcg_list.append(ndcg_at_k(recommended, relevant, k))\n",
    "    map_list.append(map_at_k(recommended, relevant, k))\n",
    "\n",
    "# Final Metrics Report\n",
    "print(f\"\\nEvaluation Results (k={k}):\")\n",
    "print(f\"Precision@{k}: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Recall@{k}:    {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{k}:      {np.mean(ndcg_list):.4f}\")\n",
    "print(f\"MAP@{k}:       {np.mean(map_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862aadb",
   "metadata": {},
   "source": [
    "\n",
    "Evaluation Results (k=10):\n",
    "\n",
    "Precision@10: 0.0050\n",
    "\n",
    "Recall@10:    0.0499\n",
    "\n",
    "NDCG@10:      0.0299\n",
    "\n",
    "MAP@10:       0.0238"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
