{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c35f484",
   "metadata": {},
   "source": [
    "NCF Recommenders Library Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Collaborative Filtering (NCF) with MovieLens 1M\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.models.ncf.ncf_singlenode import NCF\n",
    "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.python_splitters import python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import get_top_k_items\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "print(\"Downloading MovieLens 1M dataset...\")\n",
    "df = movielens.load_pandas_df(size=\"1m\")\n",
    "\n",
    "print(\"Data preview:\")\n",
    "print(df.head())\n",
    "\n",
    "ratings = df.rename(columns={\"userID\": \"userID\", \"itemID\": \"itemID\", \"rating\": \"rating\"})\n",
    "\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=SEED)\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "train_df = train_df.sort_values(by=\"userID\")\n",
    "test_df = test_df.sort_values(by=\"userID\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    train_path = os.path.join(temp_dir, \"train.csv\")\n",
    "    test_path = os.path.join(temp_dir, \"test.csv\")\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "\n",
    "    print(\"Converting to NCFDataset...\")\n",
    "    data = NCFDataset(train_file=train_path, test_file=test_path, seed=SEED)\n",
    "\n",
    "    print(\"Initializing NCF model...\")\n",
    "    ncf_model = NCF(\n",
    "        n_users=data.n_users,\n",
    "        n_items=data.n_items,\n",
    "        model_type=\"NeuMF\",  # Options: \"NeuMF\", \"GMF\", \"MLP\"\n",
    "        learning_rate=0.001,\n",
    "        batch_size=256,\n",
    "        verbose=10,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    with Timer() as train_time:\n",
    "        ncf_model.fit(data)\n",
    "\n",
    "    print(f\"Training took: {train_time}\")\n",
    "\n",
    "    print(\"Generating top-K predictions...\")\n",
    "    top_k = 10\n",
    "\n",
    "    # Only use users and items seen during training\n",
    "    known_users = set(train_df[\"userID\"].unique())\n",
    "    known_items = set(train_df[\"itemID\"].unique())\n",
    "\n",
    "    test_users = test_df[test_df.userID.isin(known_users)].userID.unique()\n",
    "    all_items = df[df.itemID.isin(known_items)].itemID.unique()\n",
    "\n",
    "    user_input, item_input = [], []\n",
    "    for u in test_users:\n",
    "        user_input.extend([u] * len(all_items))\n",
    "        item_input.extend(all_items)\n",
    "\n",
    "    scores = ncf_model.predict(user_input, item_input, is_list=True)\n",
    "    all_preds = pd.DataFrame({\"userID\": user_input, \"itemID\": item_input, \"prediction\": scores})\n",
    "    all_preds.rename(columns={\"prediction\": \"rating\"}, inplace=True)\n",
    "    top_k_preds = get_top_k_items(all_preds, k=top_k)\n",
    "    top_k_preds[\"prediction\"] = top_k_preds[\"rating\"]  # copy predicted score\n",
    "    top_k_preds[\"rating\"] = 1  # dummy relevancy score\n",
    "    top_k_preds = top_k_preds[[\"userID\", \"itemID\", \"rating\", \"prediction\"]].astype({\n",
    "        \"userID\": int, \"itemID\": int, \"rating\": int, \"prediction\": float\n",
    "    })\n",
    "\n",
    "    test_df_filtered = test_df[test_df.userID.isin(test_users) & test_df.itemID.isin(known_items)].copy()\n",
    "    test_df_filtered = test_df_filtered[[\"userID\", \"itemID\", \"rating\"]].astype({\n",
    "        \"userID\": int, \"itemID\": int, \"rating\": int\n",
    "    })\n",
    "\n",
    "    print(\"Evaluating model (Top-K metrics)...\")\n",
    "    k = 10\n",
    "    print(f\"MAP@{k}: {map_at_k(test_df_filtered, top_k_preds, col_prediction='prediction', k=k):.4f}\")\n",
    "    print(f\"NDCG@{k}: {ndcg_at_k(test_df_filtered, top_k_preds, col_prediction='prediction', k=k):.4f}\")\n",
    "    print(f\"Precision@{k}: {precision_at_k(test_df_filtered, top_k_preds, col_prediction='prediction', k=k):.4f}\")\n",
    "    print(f\"Recall@{k}: {recall_at_k(test_df_filtered, top_k_preds, col_prediction='prediction', k=k):.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862aadb",
   "metadata": {},
   "source": [
    "MAP@10: 0.0558\n",
    "\n",
    "NDCG@10: 0.1354\n",
    "\n",
    "Precision@10: 0.1248\n",
    "\n",
    "Recall@10: 0.0728"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
