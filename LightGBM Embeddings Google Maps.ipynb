{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c35f484",
   "metadata": {},
   "source": [
    "LightGBM Embeddings Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q lightgbm tqdm sentence-transformers\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "file_path = '/content/drive/MyDrive/review-South_Carolina_10.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "df = pd.DataFrame(data).sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Text cleaning\n",
    "def clean_text(text, max_words=80):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    return ' '.join(text.split()[:max_words])\n",
    "\n",
    "df['text'] = df['text'].fillna('').apply(clean_text)\n",
    "\n",
    "# Feature engineering\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['num_exclamations'] = df['text'].str.count('!')\n",
    "df['time'] = pd.to_datetime(df['time'], unit='ms', errors='coerce')\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['weekday'] = df['time'].dt.weekday\n",
    "df['month'] = df['time'].dt.month\n",
    "df['time_of_day'] = df['hour'].apply(\n",
    "    lambda h: 'morning' if 5 <= h < 12 else\n",
    "              'afternoon' if 12 <= h < 17 else\n",
    "              'evening' if 17 <= h < 21 else 'night'\n",
    ").astype('category')\n",
    "df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "df['days_since_review'] = (df['time'].max() - df['time']).dt.days\n",
    "df['user_id'] = df['user_id'].astype('category')\n",
    "df['gmap_id'] = df['gmap_id'].astype('category')\n",
    "y = df['rating'] - 1\n",
    "\n",
    "# Structured features\n",
    "simple_features = [\n",
    "    'hour', 'weekday', 'month', 'is_weekend',\n",
    "    'time_of_day', 'days_since_review',\n",
    "    'text_length', 'num_exclamations'\n",
    "]\n",
    "X_simple = df[simple_features].reset_index(drop=True)\n",
    "categorical_features = ['time_of_day']\n",
    "\n",
    "# Embedding setup\n",
    "embedding_path = '/content/drive/MyDrive/full_embeddings.npy'\n",
    "texts = df['text'].tolist()\n",
    "total_rows = len(texts)\n",
    "embedding_dim = 384\n",
    "\n",
    "if os.path.exists(embedding_path):\n",
    "    print(\"Embedding file already exists, skipping recomputation.\")\n",
    "else\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "    embedder.half()\n",
    "    batch_size = 1024\n",
    "    embedding_dim = embedder.encode([\"test\"], device='cuda', convert_to_numpy=True).shape[1]\n",
    "    embedding_array = np.memmap(embedding_path, dtype='float16', mode='w+', shape=(total_rows, embedding_dim))\n",
    "\n",
    "    print(\"Embedding text to Google Drive...\")\n",
    "    cursor = 0\n",
    "    for i in tqdm(range(0, total_rows, batch_size), desc=\"Embedding\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        emb = embedder.encode(batch, batch_size=batch_size, device='cuda', convert_to_numpy=True)\n",
    "        embedding_array[cursor:cursor+len(emb)] = emb.astype('float16')\n",
    "        cursor += len(emb)\n",
    "        del batch, emb\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    embedding_array.flush()\n",
    "    del embedding_array\n",
    "    gc.collect()\n",
    "    print(\"Embeddings saved.\")\n",
    "\n",
    "embedding_loaded = np.memmap(embedding_path, dtype='float16', mode='r', shape=(total_rows, embedding_dim))\n",
    "embedding_df = pd.DataFrame(embedding_loaded)\n",
    "\n",
    "X = pd.concat([X_simple.reset_index(drop=True), embedding_df.reset_index(drop=True)], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 5,\n",
    "    'verbosity': -1,\n",
    "    'device': 'gpu',\n",
    "    'max_bin': 255\n",
    "}\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "acc = accuracy_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels, average='weighted')\n",
    "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "embed_lookup_df = pd.concat([df[['gmap_id']].reset_index(drop=True), embedding_df], axis=1)\n",
    "gmap_id_to_embedding = embed_lookup_df.groupby('gmap_id').first().to_dict(orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862aadb",
   "metadata": {},
   "source": [
    "Test Accuracy: 0.6183\n",
    "\n",
    "Test F1 Score: 0.5009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommender_metrics(model, df, gmap_id_to_embedding,\n",
    "                                 user_col='user_id', item_col='gmap_id',\n",
    "                                 K_list=[5, 10, 20], num_negatives=99):\n",
    "    print(\"Evaluating Recommender Metrics\")\n",
    "\n",
    "    user_items = defaultdict(set)\n",
    "    for uid, gid in zip(df[user_col], df[item_col]):\n",
    "        user_items[uid].add(gid)\n",
    "\n",
    "    all_items = df[item_col].unique().tolist()\n",
    "    test_users = df[user_col].unique()\n",
    "    embedding_dim = len(next(iter(gmap_id_to_embedding.values())))\n",
    "\n",
    "    results_by_k = {k: {'recall': [], 'precision': [], 'hit': [], 'ndcg': []} for k in K_list}\n",
    "\n",
    "    for user in tqdm(test_users, desc=\"Users\"):\n",
    "        user_df = df[df[user_col] == user]\n",
    "        if user_df.empty:\n",
    "            continue\n",
    "        pos_item = user_df.sample(1, random_state=42)[item_col].values[0]\n",
    "\n",
    "        negatives = random.sample(\n",
    "            [item for item in all_items if item not in user_items[user]],\n",
    "            min(num_negatives, len(all_items) - len(user_items[user]) - 1)\n",
    "        )\n",
    "        candidates = [pos_item] + negatives\n",
    "        candidate_labels = [1] + [0] * len(negatives)\n",
    "\n",
    "        rows = []\n",
    "        for item in candidates:\n",
    "            row = user_df.iloc[0].copy()\n",
    "            row[item_col] = item\n",
    "            rows.append(row)\n",
    "\n",
    "        test_batch = pd.DataFrame(rows)\n",
    "        test_batch['time_of_day'] = test_batch['time_of_day'].astype('category')\n",
    "\n",
    "        features = [\n",
    "            'hour', 'weekday', 'month', 'is_weekend',\n",
    "            'time_of_day', 'days_since_review',\n",
    "            'text_length', 'num_exclamations'\n",
    "        ]\n",
    "        X_struct = test_batch[features].reset_index(drop=True)\n",
    "\n",
    "        X_embed = pd.DataFrame([\n",
    "            gmap_id_to_embedding.get(item, {i: 0 for i in range(embedding_dim)})\n",
    "            for item in candidates\n",
    "        ])\n",
    "        X_batch = pd.concat([X_struct, X_embed], axis=1)\n",
    "\n",
    "        scores = model.predict(X_batch)\n",
    "        scores = scores[:, -1] if scores.ndim == 2 else scores\n",
    "\n",
    "        ranked_indices = np.argsort(-scores)\n",
    "        ranked_labels = np.array(candidate_labels)[ranked_indices]\n",
    "\n",
    "        for k in K_list:\n",
    "            top_k = ranked_labels[:k]\n",
    "            hit = int(1 in top_k)\n",
    "            rank = np.where(ranked_labels == 1)[0][0] + 1\n",
    "            ndcg = 1.0 / np.log2(rank + 1) if rank <= k else 0\n",
    "            precision = top_k.sum() / k\n",
    "            recall = 1.0 if 1 in top_k else 0\n",
    "\n",
    "            results_by_k[k]['recall'].append(recall)\n",
    "            results_by_k[k]['precision'].append(precision)\n",
    "            results_by_k[k]['hit'].append(hit)\n",
    "            results_by_k[k]['ndcg'].append(ndcg)\n",
    "\n",
    "    print(\"\\n Ranking Metrics:\")\n",
    "    for k in K_list:\n",
    "        recall = np.mean(results_by_k[k]['recall'])\n",
    "        precision = np.mean(results_by_k[k]['precision'])\n",
    "        hit = np.mean(results_by_k[k]['hit'])\n",
    "        ndcg = np.mean(results_by_k[k]['ndcg'])\n",
    "        print(f\"@{k}: Recall={recall:.4f}, Precision={precision:.4f}, HitRate={hit:.4f}, NDCG={ndcg:.4f}\")\n",
    "\n",
    "evaluate_recommender_metrics(\n",
    "    model=model,\n",
    "    df=df,\n",
    "    gmap_id_to_embedding=gmap_id_to_embedding,\n",
    "    user_col='user_id',\n",
    "    item_col='gmap_id',\n",
    "    K_list=[5, 10, 20],\n",
    "    num_negatives=99\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f7557",
   "metadata": {},
   "source": [
    "Ranking Metrics:\n",
    "\n",
    "@5: Recall=0.0410, Precision=0.0082, HitRate=0.0410, NDCG=0.0284\n",
    "\n",
    "@10: Recall=0.0845, Precision=0.0085, HitRate=0.0845, NDCG=0.0423\n",
    "\n",
    "@20: Recall=0.1712, Precision=0.0086, HitRate=0.1712, NDCG=0.0639"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
